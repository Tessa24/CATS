{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# features selection libraries\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#import libraries models\n",
    "from sklearn import model_selection, metrics, grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAUTION! when importing the file the arrays nummer which were previously the names of the rows are no in a column!(take a look at the table) So we have to adjust this for the test and training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../data/train_features.csv')\n",
    "y_train = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct columns and names of rows for train (will do test data later). For some reason when importing the saved x_train and y_trian data pandas puts the names of the rows in a seperate columns. Thus adding an additional column (see x and y train after importing it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename rows of x_train\n",
    "x_train = x_train.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in x_train.arrays:\n",
    "    x_train = x_train.rename(index = {array : i})\n",
    "    array +=1\n",
    "x_train = x_train.drop('arrays', axis =1)\n",
    "\n",
    "# rename rows of y_train\n",
    "y_train = y_train.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in y_train.arrays:\n",
    "    y_train = y_train.rename(index = {array : i})\n",
    "    array +=1\n",
    "y_train = y_train.drop('arrays', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train['Subgroups'] = y_train['Subgroups'].map(lambda x: x.strip('\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, RFE features selection might take a couple of minutes when testing for multiple parameters. \n",
    "\n",
    "In the paper they SVM as estimator and uses different penalties for C\n",
    "for the SVM estimator for optimization.\n",
    "C penalties used: 0.25, 1, 4, 16, 64, 256\n",
    "\n",
    "To find out which of these have the best score for feature selection I will make a for loop and define the score for each feature selection for the different C parameters.\n",
    "\n",
    "I am not entirely sure about this..... it says so in the paper but to me it somehow feels odd to do hyperparameter selection on the estimator of RFE.... maybe discuss this in monday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which C penalties gives best score for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select best SVC c penalty for 8 features\n",
    "c_range = [0.25, 1, 4, 16, 64, 256]\n",
    "scores = []\n",
    "for i in c_range:\n",
    "    estimator = svm.SVC(kernel = 'linear', C=i)\n",
    "    selector_8f = RFE(estimator, 8)\n",
    "    selector_8f = selector_8f.fit(x_train,y_train.values.ravel())\n",
    "    scores.append(selector_8f.score(x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9875, 0.9875, 0.9875, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use parameter with best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apperently from 16 onward the score was the highest namely 1.0 so I used 16 for the C parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection for 8 features with best C score(=16)\n",
    "estimator = svm.SVC(kernel ='linear', C=16) # in the paper they used SVC as the estimator (see appendix)\n",
    "selector_RFE8 = RFE(estimator, 8)\n",
    "selector_RFE8 = selector_RFE8.fit(x_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the feature columns are label 0 to 2833 we can see which columns are selected by finding the TRUE items in selector_8f.support_. This command gives you an array with true or false. If the feature are that position was selected it is label true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 771, 1062, 1655, 1677, 2030, 2184, 2213, 2750], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find selected features\n",
    "selector_RFE8.get_support(indices = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 8)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RFE8 = selector_RFE8.transform(x_train)\n",
    "x_train_RFE8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which C penalties gives best score for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best SVC c penalty for 32 features\n",
    "c_range = [0.25, 1, 4, 16, 64, 256]\n",
    "scores = []\n",
    "for i in c_range:\n",
    "    estimator = svm.SVC(kernel = 'linear', C=i)\n",
    "    selector_32f = RFE(estimator, 32)\n",
    "    selector_32f = selector_32f.fit(x_train,y_train.values.ravel())\n",
    "    scores.append(selector_32f.score(x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use parameter with best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this one all of them have a score of 1.0 so I'll use the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection for 32 features for best C score(=)\n",
    "\n",
    "estimator = svm.SVC(kernel ='linear')\n",
    "selector_RFE32 = RFE(estimator, 32)\n",
    "selector_RFE32 = selector_32f.fit(x_train,y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 190,  192,  226,  673,  762,  768,  771,  772,  854, 1035, 1062,\n",
       "       1243, 1562, 1569, 1655, 1657, 1677, 1773, 1900, 1962, 2021, 2024,\n",
       "       2030, 2079, 2125, 2183, 2184, 2213, 2214, 2548, 2655, 2750],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find selected features\n",
    "selector_RFE32.get_support(indices = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RFE32 = selector_RFE32.transform(x_train)\n",
    "x_train_RFE32.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 94 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which C penalties gives best score for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best SVC c penalty for 32 features\n",
    "c_range = [0.25, 1, 4, 16, 64, 256]\n",
    "scores = []\n",
    "for i in c_range:\n",
    "    estimator = svm.SVC(kernel = 'linear', C=i)\n",
    "    selector_94f = RFE(estimator, 94)\n",
    "    selector_94f = selector_94f.fit(x_train,y_train.values.ravel())\n",
    "    scores.append(selector_94f.score(x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use parameter with best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the score were all 1.0 so I took the default C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41,  190,  192,  194,  226,  262,  463,  486,  672,  673,  762,\n",
       "        765,  768,  769,  771,  772,  792,  849,  854,  855,  998,  999,\n",
       "       1009, 1032, 1035, 1062, 1111, 1114, 1243, 1244, 1245, 1352, 1401,\n",
       "       1561, 1562, 1569, 1596, 1655, 1657, 1663, 1677, 1773, 1812, 1817,\n",
       "       1870, 1876, 1900, 1902, 1960, 1962, 1971, 1972, 2019, 2021, 2024,\n",
       "       2029, 2030, 2032, 2056, 2068, 2070, 2078, 2079, 2125, 2126, 2182,\n",
       "       2183, 2184, 2185, 2186, 2202, 2206, 2207, 2210, 2213, 2214, 2217,\n",
       "       2218, 2515, 2528, 2547, 2548, 2549, 2655, 2734, 2748, 2749, 2750,\n",
       "       2752, 2760, 2770, 2771, 2816, 2826], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 94 features for best C score(=)\n",
    "estimator = svm.SVC(kernel ='linear')\n",
    "selector_RFE94 = RFE(estimator, 94)\n",
    "selector_RFE94 = selector_RFE94.fit(x_train,y_train.values.ravel())\n",
    "selector_RFE94.get_support(indices = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41,  190,  192,  194,  226,  262,  463,  486,  672,  673,  762,\n",
       "        765,  768,  769,  771,  772,  792,  849,  854,  855,  998,  999,\n",
       "       1009, 1032, 1035, 1062, 1111, 1114, 1243, 1244, 1245, 1352, 1401,\n",
       "       1561, 1562, 1569, 1596, 1655, 1657, 1663, 1677, 1773, 1812, 1817,\n",
       "       1870, 1876, 1900, 1902, 1960, 1962, 1971, 1972, 2019, 2021, 2024,\n",
       "       2029, 2030, 2032, 2056, 2068, 2070, 2078, 2079, 2125, 2126, 2182,\n",
       "       2183, 2184, 2185, 2186, 2202, 2206, 2207, 2210, 2213, 2214, 2217,\n",
       "       2218, 2515, 2528, 2547, 2548, 2549, 2655, 2734, 2748, 2749, 2750,\n",
       "       2752, 2760, 2770, 2771, 2816, 2826], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 32 features\n",
    "selector_RFE94.get_support(indices = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 94)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RFE94 = selector_RFE94.transform(x_train)\n",
    "x_train_RFE94.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This methode does feature selection using univariate statistics. See http://scikit-learn.org/stable/modules/feature_selection.html for more info.\n",
    "In this case I used f_classif, which makes the selector use ANOVA to select the best K features of the model.\n",
    "\n",
    "In the paper no parameter selection was done for ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 8)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 8 features ANOVA\n",
    "selector_ANOVA8= SelectKBest(f_classif, k=8).fit(x_train,y_train.values.ravel())\n",
    "x_train_ANOVA8 = selector_ANOVA8.transform(x_train)\n",
    "x_train_ANOVA8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 461,  463,  464,  672,  673,  819,  837,  839,  840,  842,  843,\n",
       "        844,  845,  846,  847,  848,  849,  850,  851,  852,  853,  854,\n",
       "        855,  856,  857,  861,  999, 1000, 1001, 1002, 1004, 1642, 1643,\n",
       "       1645, 1646, 1647, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1659,\n",
       "       1660, 1662, 1663, 1664, 1665, 1667, 1668, 1669, 1670, 1671, 1672,\n",
       "       1673, 1674, 1676, 1677, 1678, 1679, 1687, 1971, 1972, 1973, 2019,\n",
       "       2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2032, 2033,\n",
       "       2034, 2035, 2036, 2038, 2039, 2040, 2184, 2206, 2207, 2210, 2213,\n",
       "       2214, 2223, 2748, 2749, 2750, 2751], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 32 features ANOVA\n",
    "selector_ANOVA32= SelectKBest(f_classif, k=32).fit(x_train,y_train.values.ravel())\n",
    "x_train_ANOVA32 = selector_ANOVA32.transform(x_train)\n",
    "x_train_ANOVA32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 461,  463,  464,  672,  673,  819,  837,  839,  840,  842,  843,\n",
       "        844,  845,  846,  847,  848,  849,  850,  851,  852,  853,  854,\n",
       "        855,  856,  857,  861,  999, 1000, 1001, 1002, 1004, 1642, 1643,\n",
       "       1645, 1646, 1647, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1659,\n",
       "       1660, 1662, 1663, 1664, 1665, 1667, 1668, 1669, 1670, 1671, 1672,\n",
       "       1673, 1674, 1676, 1677, 1678, 1679, 1687, 1971, 1972, 1973, 2019,\n",
       "       2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2032, 2033,\n",
       "       2034, 2035, 2036, 2038, 2039, 2040, 2184, 2206, 2207, 2210, 2213,\n",
       "       2214, 2223, 2748, 2749, 2750, 2751], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 94 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection for 94 features ANOVA\n",
    "selector_ANOVA94= SelectKBest(f_classif, k=94).fit(x_train,y_train.values.ravel())\n",
    "x_train_ANOVA94 = selector_ANOVA94.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 461,  463,  464,  672,  673,  819,  837,  839,  840,  842,  843,\n",
       "        844,  845,  846,  847,  848,  849,  850,  851,  852,  853,  854,\n",
       "        855,  856,  857,  861,  999, 1000, 1001, 1002, 1004, 1642, 1643,\n",
       "       1645, 1646, 1647, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1659,\n",
       "       1660, 1662, 1663, 1664, 1665, 1667, 1668, 1669, 1670, 1671, 1672,\n",
       "       1673, 1674, 1676, 1677, 1678, 1679, 1687, 1971, 1972, 1973, 2019,\n",
       "       2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2032, 2033,\n",
       "       2034, 2035, 2036, 2038, 2039, 2040, 2184, 2206, 2207, 2210, 2213,\n",
       "       2214, 2223, 2748, 2749, 2750, 2751], dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification methodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest-Neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to do hyperparameter optimization. in the paper they optimize for: k_neighbors, Distance function and weight function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "# define the parameter range that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "dist_func = [1,2]# 1 = manhattan, 2= Euclidean\n",
    "dist_weight = ['uniform', 'distance']\n",
    "\n",
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range, p=dist_func,weights=dist_weight)\n",
    "\n",
    "# instantiate the grid\n",
    "grid_search= GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit parameters for all features RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.95\n",
      "Best parameters for 8 features: {'n_neighbors': 16, 'p': 2, 'weights': 'distance'}\n",
      "Best score for 32 features: 0.9625\n",
      "Best parameters for 32 features: {'n_neighbors': 11, 'p': 2, 'weights': 'distance'}\n",
      "Best score for 94 features: 0.875\n",
      "Best parameters for 94 features: {'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8 features\n",
    "grid_RFE8 = grid_search.fit(x_train_RFE8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_RFE32 = grid_search.fit(x_train_RFE32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_RFE94 = grid_search.fit(x_train_RFE94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 8 features the best outcome was: k = 16 | p = euclidean distance | weights = distance\n",
    "\n",
    "For 32 features the best outcome was: k = 11 | p = euclidean distance | weights = distance\n",
    "\n",
    "For 94 features the best outcome was: k = 10 | p = euclidean distance | weights = distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit parameters for all features ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.8375\n",
      "Best parameters for 8 features: {'n_neighbors': 15, 'p': 2, 'weights': 'distance'}\n",
      "Best score for 32 features: 0.8625\n",
      "Best parameters for 32 features: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "Best score for 94 features: 0.8375\n",
      "Best parameters for 94 features: {'n_neighbors': 8, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_ANOVA8 = grid_search.fit(x_train_ANOVA8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_ANOVA32 = grid_search.fit(x_train_ANOVA32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_ANOVA94 = grid_search.fit(x_train_ANOVA94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 8 features the best outcome was: k = 15 | p = euclidean distance | weights = distance\n",
    "\n",
    "For 32 features the best outcome was: k = 6 | p = euclidean distance | weights = uniform\n",
    "\n",
    "For 94 features the best outcome was: k = 8 | p = euclidean distance | weights = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make knn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "knn_model_RFE8 = KNeighborsClassifier(n_neighbors = 16, p = 2, weights = 'distance')\n",
    "knn_model_RFE8.fit(x_train_RFE8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "knn_model_RFE32 = KNeighborsClassifier(n_neighbors = 11, p = 2, weights = 'distance')\n",
    "knn_model_RFE32.fit(x_train_RFE32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "knn_model_RFE94 = KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance')\n",
    "knn_model_RFE94.fit(x_train_RFE94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-3deae12abd2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknn_model_RFE32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "knn_model_ANOVA8 = KNeighborsClassifier(n_neighbors = 15, p = 2, weights = 'distance')\n",
    "knn_model_ANOVA8.fit(x_train_ANOVA8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "knn_model_ANOVA32 = KNeighborsClassifier(n_neighbors = 6, p = 2, weights = 'uniform')\n",
    "knn_model_ANOVA32.fit(x_train_ANOVA32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "knn_model_ANOVA94 = KNeighborsClassifier(n_neighbors = 8, p = 2, weights = 'distance')\n",
    "knn_model_ANOVA94.fit(x_train_ANOVA94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('../data/test_features.csv')\n",
    "y_test = pd.read_csv('../data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename rows of x_train\n",
    "x_test = x_test.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in x_test.arrays:\n",
    "    x_test = x_test.rename(index = {array : i})\n",
    "    array +=1\n",
    "x_test = x_test.drop('arrays', axis =1)\n",
    "\n",
    "# rename rows of y_train\n",
    "y_test = y_test.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in y_test.arrays:\n",
    "    y_test = y_test.rename(index = {array : i})\n",
    "    array +=1\n",
    "y_test = y_test.drop('arrays', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take selected features per selection methode from test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8)\n",
      "(20, 32)\n",
      "(20, 94)\n"
     ]
    }
   ],
   "source": [
    "# x_test for 8 features RFE\n",
    "x_test_RFE8 = x_test[x_test.columns[selector_RFE8.get_support(indices = True)]]\n",
    "# x_test for 32 features\n",
    "x_test_RFE32 = x_test[x_test.columns[selector_RFE32.get_support(indices = True)]]\n",
    "# x_test for 94 features\n",
    "x_test_RFE94 = x_test[x_test.columns[selector_RFE94.get_support(indices = True)]]\n",
    "\n",
    "print(x_test_RFE8.shape)\n",
    "print(x_test_RFE32.shape)\n",
    "print(x_test_RFE94.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8)\n",
      "(20, 32)\n",
      "(20, 94)\n"
     ]
    }
   ],
   "source": [
    "# x_test for 8 features ANOVA\n",
    "x_test_ANOVA8 = x_test[x_test.columns[selector_ANOVA8.get_support(indices = True)]]\n",
    "# x_test for 32 features\n",
    "x_test_ANOVA32 = x_test[x_test.columns[selector_ANOVA32.get_support(indices = True)]]\n",
    "# x_test for 94 features\n",
    "x_test_ANOVA94 = x_test[x_test.columns[selector_ANOVA94.get_support(indices = True)]]\n",
    "\n",
    "print(x_test_RFE8.shape)\n",
    "print(x_test_RFE32.shape)\n",
    "print(x_test_RFE94.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction RFE (STILL HAVE TO DO THIS FOR TEST DATA!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature RFE:  1.0\n",
      "accuracy for 32 features RFE:  1.0\n",
      "accuracy for 94 features RFE:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_RFE8 = knn_model_RFE8.predict(x_train_RFE8) # will do for test data\n",
    "print('accuracy for 8 feature RFE: ',metrics.accuracy_score(y_train, y_predict_RFE8))\n",
    "# 32 features\n",
    "y_predict_RFE32 = knn_model_RFE32.predict(x_train_RFE32) # will do for test data\n",
    "print('accuracy for 32 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE32))\n",
    "# 94 features\n",
    "y_predict_RFE94 = knn_model_RFE94.predict(x_train_RFE94) # will do for test data\n",
    "print('accuracy for 94 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE94))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction ANOVA (STILL HAVE TO DO THIS FOR TEST DATA!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature ANOVA:  0.8875\n",
      "accuracy for 32 features ANOVA:  0.9\n",
      "accuracy for 94 features ANOVA:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_ANOVA8 = knn_model_ANOVA8.predict(x_train_ANOVA8) # will do for test data\n",
    "print('accuracy for 8 feature ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA8))\n",
    "# 32 features\n",
    "y_predict_ANOVA32 = knn_model_ANOVA32.predict(x_train_ANOVA32) # will do for test data\n",
    "print('accuracy for 32 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA32))\n",
    "# 94 features\n",
    "y_predict_ANOVA94 = knn_model_ANOVA94.predict(x_train_ANOVA94) # will do for test data\n",
    "print('accuracy for 94 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA94))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
