{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# features selection libraries\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#import libraries models\n",
    "from sklearn import model_selection, metrics, grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAUTION! when importing the file the arrays nummer which were previously the names of the rows are no in a column!(take a look at the table) So we have to adjust this for the test and training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../data/train_features.csv')\n",
    "y_train = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct columns and names of rows for train (will do test data later). For some reason when importing the saved x_train and y_trian data pandas puts the names of the rows in a seperate columns. Thus adding an additional column (see x and y train after importing it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename rows of x_train\n",
    "x_train = x_train.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in x_train.arrays:\n",
    "    x_train = x_train.rename(index = {array : i})\n",
    "    array +=1\n",
    "x_train = x_train.drop('arrays', axis =1)\n",
    "\n",
    "# rename rows of y_train\n",
    "y_train = y_train.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in y_train.arrays:\n",
    "    y_train = y_train.rename(index = {array : i})\n",
    "    array +=1\n",
    "y_train = y_train.drop('arrays', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train['Subgroups'] = y_train['Subgroups'].map(lambda x: x.strip('\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, RFE features selection might take a couple of minutes when testing for multiple parameters. \n",
    "\n",
    "In the paper they SVM as estimator and uses different penalties for C\n",
    "for the SVM estimator for optimization.\n",
    "C penalties used: 0.25, 1, 4, 16, 64, 256\n",
    "\n",
    "Use the GridSearchCV function scikit-learn provides to search for best C penalty parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which C penalties gives best score for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RFE(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "  n_features_to_select=8, step=1, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.25, 1, 4, 16, 64, 256]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select best SVC c penalty for 8 features\n",
    "c_range = [0.25, 1, 4, 16, 64, 256]\n",
    "\n",
    "estimator = svm.SVC(kernel=\"linear\")\n",
    "selector_8f = RFE(estimator,8)\n",
    "grid8 = GridSearchCV(selector_8f, param_grid={'estimator__C': [0.25, 1, 4, 16, 64, 256]})\n",
    "grid8.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__C': 0.25}\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "print(grid8.best_params_)\n",
    "print(grid8.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use parameter with best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection for 8 features with best C score(=0.25)\n",
    "estimator = svm.SVC(kernel ='linear', C=0.25) # in the paper they used SVC as the estimator (see appendix)\n",
    "selector_RFE8 = RFE(estimator, 8)\n",
    "selector_RFE8 = selector_RFE8.fit(x_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the feature columns are label 0 to 2833 we can see which columns are selected by finding the TRUE items in selector_8f.support_. This command gives you an array with true or false. If the feature are that position was selected it is label true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 192, 1062, 1677, 1900, 2024, 2184, 2213, 2750], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find selected features\n",
    "selector_RFE8.get_support(indices = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RFE8 = selector_RFE8.transform(x_train)\n",
    "x_train_RFE8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which C penalties gives best score for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RFE(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "  n_features_to_select=32, step=1, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.25, 1, 4, 16, 64, 256]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select best SVC c penalty for 32 features using gridsearchCV\n",
    "\n",
    "estimator = svm.SVC(kernel=\"linear\")\n",
    "selector_32f = RFE(estimator,32)\n",
    "grid32 = GridSearchCV(selector_32f, param_grid={'estimator__C': [0.25, 1, 4, 16, 64, 256]})\n",
    "grid32.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__C': 0.25}\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(grid32.best_params_)\n",
    "print(grid32.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use parameter with best score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection for 32 features for best C score(=0.25)\n",
    "\n",
    "estimator = svm.SVC(kernel ='linear', C=0.25)\n",
    "selector_RFE32 = RFE(estimator, 32)\n",
    "selector_RFE32 = selector_RFE32.fit(x_train,y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 190,  192,  226,  673,  762,  768,  771,  772,  854, 1035, 1062,\n",
       "       1243, 1562, 1569, 1655, 1657, 1677, 1773, 1900, 1962, 2021, 2024,\n",
       "       2030, 2079, 2125, 2183, 2184, 2213, 2214, 2548, 2655, 2750], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find selected features\n",
    "selector_RFE32.get_support(indices = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RFE32 = selector_RFE32.transform(x_train)\n",
    "x_train_RFE32.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 94 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which C penalties gives best score for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RFE(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "  n_features_to_select=94, step=1, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__C': [0.25, 1, 4, 16, 64, 256]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select best SVC c penalty for 32 features using gridsearchCV\n",
    "\n",
    "estimator = svm.SVC(kernel=\"linear\")\n",
    "selector_94f = RFE(estimator,94)\n",
    "grid94 = GridSearchCV(selector_94f, param_grid={'estimator__C': [0.25, 1, 4, 16, 64, 256]})\n",
    "grid94.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__C': 0.25}\n",
      "0.7625\n"
     ]
    }
   ],
   "source": [
    "print(grid94.best_params_)\n",
    "print(grid94.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use parameter with best score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41,  190,  192,  194,  226,  262,  463,  486,  672,  673,  762,\n",
       "        765,  768,  769,  771,  772,  792,  849,  854,  855,  998,  999,\n",
       "       1009, 1032, 1035, 1062, 1111, 1114, 1243, 1244, 1245, 1352, 1401,\n",
       "       1561, 1562, 1569, 1596, 1655, 1657, 1663, 1677, 1773, 1812, 1817,\n",
       "       1870, 1876, 1900, 1902, 1960, 1962, 1971, 1972, 2019, 2021, 2024,\n",
       "       2029, 2030, 2032, 2056, 2068, 2070, 2078, 2079, 2125, 2126, 2182,\n",
       "       2183, 2184, 2185, 2186, 2202, 2206, 2207, 2210, 2213, 2214, 2217,\n",
       "       2218, 2515, 2528, 2547, 2548, 2549, 2655, 2734, 2748, 2749, 2750,\n",
       "       2752, 2760, 2770, 2771, 2816, 2826], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 94 features for best C score(=0.25)\n",
    "estimator = svm.SVC(kernel ='linear' , C = 0.25)\n",
    "selector_RFE94 = RFE(estimator, 94)\n",
    "selector_RFE94 = selector_RFE94.fit(x_train,y_train.values.ravel())\n",
    "selector_RFE94.get_support(indices = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41,  190,  192,  194,  226,  262,  463,  486,  672,  673,  762,\n",
       "        765,  768,  769,  771,  772,  792,  849,  854,  855,  998,  999,\n",
       "       1009, 1032, 1035, 1062, 1111, 1114, 1243, 1244, 1245, 1352, 1401,\n",
       "       1561, 1562, 1569, 1596, 1655, 1657, 1663, 1677, 1773, 1812, 1817,\n",
       "       1870, 1876, 1900, 1902, 1960, 1962, 1971, 1972, 2019, 2021, 2024,\n",
       "       2029, 2030, 2032, 2056, 2068, 2070, 2078, 2079, 2125, 2126, 2182,\n",
       "       2183, 2184, 2185, 2186, 2202, 2206, 2207, 2210, 2213, 2214, 2217,\n",
       "       2218, 2515, 2528, 2547, 2548, 2549, 2655, 2734, 2748, 2749, 2750,\n",
       "       2752, 2760, 2770, 2771, 2816, 2826], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 32 features\n",
    "selector_RFE94.get_support(indices = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 94)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RFE94 = selector_RFE94.transform(x_train)\n",
    "x_train_RFE94.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This methode does feature selection using univariate statistics. See http://scikit-learn.org/stable/modules/feature_selection.html for more info.\n",
    "In this case I used f_classif, which makes the selector use ANOVA to select the best K features of the model.\n",
    "\n",
    "In the paper no parameter selection was done for ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 8 features ANOVA\n",
    "selector_ANOVA8= SelectKBest(f_classif, k=8).fit(x_train,y_train.values.ravel())\n",
    "x_train_ANOVA8 = selector_ANOVA8.transform(x_train)\n",
    "x_train_ANOVA8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 673,  849,  852,  853,  854,  855, 2184, 2213], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_ANOVA8.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection for 32 features ANOVA\n",
    "selector_ANOVA32= SelectKBest(f_classif, k=32).fit(x_train,y_train.values.ravel())\n",
    "x_train_ANOVA32 = selector_ANOVA32.transform(x_train)\n",
    "x_train_ANOVA32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 672,  673,  848,  849,  851,  852,  853,  854,  855, 1001, 1646,\n",
       "       1651, 1655, 1656, 1662, 1663, 1664, 1667, 1668, 1677, 1678, 1687,\n",
       "       1972, 2021, 2032, 2034, 2039, 2040, 2184, 2210, 2213, 2214], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_ANOVA32.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 94 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection for 94 features ANOVA\n",
    "selector_ANOVA94= SelectKBest(f_classif, k=94).fit(x_train,y_train.values.ravel())\n",
    "x_train_ANOVA94 = selector_ANOVA94.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 461,  463,  464,  672,  673,  819,  837,  839,  840,  842,  843,\n",
       "        844,  845,  846,  847,  848,  849,  850,  851,  852,  853,  854,\n",
       "        855,  856,  857,  861,  999, 1000, 1001, 1002, 1004, 1642, 1643,\n",
       "       1645, 1646, 1647, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1659,\n",
       "       1660, 1662, 1663, 1664, 1665, 1667, 1668, 1669, 1670, 1671, 1672,\n",
       "       1673, 1674, 1676, 1677, 1678, 1679, 1687, 1971, 1972, 1973, 2019,\n",
       "       2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2032, 2033,\n",
       "       2034, 2035, 2036, 2038, 2039, 2040, 2184, 2206, 2207, 2210, 2213,\n",
       "       2214, 2223, 2748, 2749, 2750, 2751], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_ANOVA94.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save selected features for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save RFE for all features (8,32 and 94)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification methodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest-Neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to do hyperparameter optimization. in the paper they optimize for: k_neighbors, Distance function and weight function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "# define the parameter range that should be searched\n",
    "k_range = list(range(1, 31))\n",
    "dist_func = [1,2]# 1 = manhattan, 2= Euclidean\n",
    "dist_weight = ['uniform', 'distance']\n",
    "\n",
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range, p=dist_func,weights=dist_weight)\n",
    "\n",
    "# instantiate the grid\n",
    "grid_search_knn= GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit parameters for all features RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.9375\n",
      "Best parameters for 8 features: {'n_neighbors': 25, 'p': 2, 'weights': 'distance'}\n",
      "Best score for 32 features: 0.9625\n",
      "Best parameters for 32 features: {'n_neighbors': 11, 'p': 2, 'weights': 'distance'}\n",
      "Best score for 94 features: 0.875\n",
      "Best parameters for 94 features: {'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_RFE8_knn = grid_search_knn.fit(x_train_RFE8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search_knn.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search_knn.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_RFE32_knn = grid_search_knn.fit(x_train_RFE32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search_knn.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search_knn.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_RFE94_knn = grid_search_knn.fit(x_train_RFE94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search_knn.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search_knn.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 8 features the best outcome was: k = 25 | p = euclidean distance | weights = distance\n",
    "\n",
    "For 32 features the best outcome was: k = 11 | p = euclidean distance | weights = distance\n",
    "\n",
    "For 94 features the best outcome was: k = 10 | p = euclidean distance | weights = distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit parameters for all features ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.8375\n",
      "Best parameters for 8 features: {'n_neighbors': 15, 'p': 2, 'weights': 'distance'}\n",
      "Best score for 32 features: 0.8625\n",
      "Best parameters for 32 features: {'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "Best score for 94 features: 0.8375\n",
      "Best parameters for 94 features: {'n_neighbors': 8, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_ANOVA8_knn = grid_search_knn.fit(x_train_ANOVA8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search_knn.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search_knn.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_ANOVA32_knn = grid_search_knn.fit(x_train_ANOVA32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search_knn.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search_knn.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_ANOVA94_knn = grid_search_knn.fit(x_train_ANOVA94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search_knn.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 8 features the best outcome was: k = 15 | p = euclidean distance | weights = distance\n",
    "\n",
    "For 32 features the best outcome was: k = 6 | p = euclidean distance | weights = uniform\n",
    "\n",
    "For 94 features the best outcome was: k = 8 | p = euclidean distance | weights = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make KNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "knn_model_RFE8 = KNeighborsClassifier(n_neighbors = 25, p = 2, weights = 'distance')\n",
    "knn_model_RFE8.fit(x_train_RFE8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "knn_model_RFE32 = KNeighborsClassifier(n_neighbors = 11, p = 2, weights = 'distance')\n",
    "knn_model_RFE32.fit(x_train_RFE32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "knn_model_RFE94 = KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance')\n",
    "knn_model_RFE94.fit(x_train_RFE94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "knn_model_ANOVA8 = KNeighborsClassifier(n_neighbors = 15, p = 2, weights = 'distance')\n",
    "knn_model_ANOVA8.fit(x_train_ANOVA8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "knn_model_ANOVA32 = KNeighborsClassifier(n_neighbors = 6, p = 2, weights = 'uniform')\n",
    "knn_model_ANOVA32.fit(x_train_ANOVA32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "knn_model_ANOVA94 = KNeighborsClassifier(n_neighbors = 8, p = 2, weights = 'distance')\n",
    "knn_model_ANOVA94.fit(x_train_ANOVA94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('../data/test_features.csv')\n",
    "y_test = pd.read_csv('../data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename rows of x_train\n",
    "x_test = x_test.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in x_test.arrays:\n",
    "    x_test = x_test.rename(index = {array : i})\n",
    "    array +=1\n",
    "x_test = x_test.drop('arrays', axis =1)\n",
    "\n",
    "# rename rows of y_train\n",
    "y_test = y_test.rename(columns= {'Unnamed: 0':'arrays'})\n",
    "\n",
    "array = 0 \n",
    "for i in y_test.arrays:\n",
    "    y_test = y_test.rename(index = {array : i})\n",
    "    array +=1\n",
    "y_test = y_test.drop('arrays', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take selected features per selection methode from test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test for 8 features RFE\n",
    "x_test_RFE8 = x_test[x_test.columns[selector_RFE8.get_support(indices = True)]]\n",
    "# x_test for 32 features\n",
    "x_test_RFE32 = x_test[x_test.columns[selector_RFE32.get_support(indices = True)]]\n",
    "# x_test for 94 features\n",
    "x_test_RFE94 = x_test[x_test.columns[selector_RFE94.get_support(indices = True)]]\n",
    "\n",
    "print(x_test_RFE8.shape)\n",
    "print(x_test_RFE32.shape)\n",
    "print(x_test_RFE94.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test for 8 features ANOVA\n",
    "x_test_ANOVA8 = x_test[x_test.columns[selector_ANOVA8.get_support(indices = True)]]\n",
    "# x_test for 32 features\n",
    "x_test_ANOVA32 = x_test[x_test.columns[selector_ANOVA32.get_support(indices = True)]]\n",
    "# x_test for 94 features\n",
    "x_test_ANOVA94 = x_test[x_test.columns[selector_ANOVA94.get_support(indices = True)]]\n",
    "\n",
    "print(x_test_RFE8.shape)\n",
    "print(x_test_RFE32.shape)\n",
    "print(x_test_RFE94.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction RFE KNN (STILL HAVE TO DO THIS FOR TEST DATA!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature RFE:  1.0\n",
      "accuracy for 32 features RFE:  1.0\n",
      "accuracy for 94 features RFE:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_RFE8_knn = knn_model_RFE8.predict(x_train_RFE8) # will do for test data\n",
    "print('accuracy for 8 feature RFE: ',metrics.accuracy_score(y_train, y_predict_RFE8_knn))\n",
    "# 32 features\n",
    "y_predict_RFE32_knn = knn_model_RFE32.predict(x_train_RFE32) # will do for test data\n",
    "print('accuracy for 32 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE32_knn))\n",
    "# 94 features\n",
    "y_predict_RFE94_knn = knn_model_RFE94.predict(x_train_RFE94) # will do for test data\n",
    "print('accuracy for 94 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE94_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction ANOVA KNN (STILL HAVE TO DO THIS FOR TEST DATA!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature ANOVA:  0.8875\n",
      "accuracy for 32 features ANOVA:  0.9\n",
      "accuracy for 94 features ANOVA:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_ANOVA8_knn = knn_model_ANOVA8.predict(x_train_ANOVA8) # will do for test data\n",
    "print('accuracy for 8 feature ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA8_knn))\n",
    "# 32 features\n",
    "y_predict_ANOVA32_knn = knn_model_ANOVA32.predict(x_train_ANOVA32) # will do for test data\n",
    "print('accuracy for 32 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA32_knn))\n",
    "# 94 features\n",
    "y_predict_ANOVA94_knn = knn_model_ANOVA94.predict(x_train_ANOVA94) # will do for test data\n",
    "print('accuracy for 94 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA94_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters from paper:\n",
    "\n",
    "Kernel Function to use as a decision function RBF and Linear\n",
    "\n",
    "RBF Gamma Kernel coefficient for RBF 0.03125, 0.125, 0.5, 2, 8, 32, 128, and 512\n",
    "\n",
    "RBF C Penalty Parameter of the error term 0.03125, 0.125, 0.5, 2, 8, 32, 128, and 512\n",
    "\n",
    "Linear C Penalty Parameter of the error term 0.03125, 0.125, 0.5, 2, 8, 32, 128, and 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter optimization SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_hyper = svm.SVC()\n",
    "kernel_type = ['linear','rbf']\n",
    "c_range = [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512]\n",
    "g_range = [0.03125, 0.125, 0.5, 2, 8, 32, 128, 512]\n",
    "params_grid_SVM = dict(C=c_range, gamma = g_range, kernel = kernel_type)\n",
    "\n",
    "grid_search_svm= GridSearchCV(svm_hyper, params_grid_SVM, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit SVM for RFE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 1.0\n",
      "Best parameters for 8 features: {'C': 8, 'gamma': 0.03125, 'kernel': 'linear'}\n",
      "Best score for 32 features: 1.0\n",
      "Best parameters for 32 features: {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'linear'}\n",
      "Best score for 94 features: 1.0\n",
      "Best parameters for 94 features: {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_RFE8_svm = grid_search_svm.fit(x_train_RFE8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search_svm.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search_svm.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_RFE32_svm = grid_search_svm.fit(x_train_RFE32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search_svm.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search_svm.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_RFE94_svm = grid_search_svm.fit(x_train_RFE94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search_svm.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for 8 features: {'C': 8, 'gamma': 0.03125, 'kernel': 'linear'}\n",
    "\n",
    "Best parameters for 32 features: {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'linear'}\n",
    "\n",
    "Best parameters for 94 features: {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit SVM for ANOVA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.85\n",
      "Best parameters for 8 features: {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "Best score for 32 features: 0.9125\n",
      "Best parameters for 32 features: {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'linear'}\n",
      "Best score for 94 features: 0.9\n",
      "Best parameters for 94 features: {'C': 0.125, 'gamma': 0.03125, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_ANOVA8_svm = grid_search_svm.fit(x_train_ANOVA8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search_svm.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search_svm.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_ANOVA32_svm = grid_search_svm.fit(x_train_ANOVA32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search_svm.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search_svm.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_ANOVA94_svm = grid_search_svm.fit(x_train_ANOVA94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search_svm.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for 8 features: {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}\n",
    "\n",
    "Best parameters for 32 features: {'C': 0.03125, 'gamma': 0.03125, 'kernel': 'linear'}\n",
    "\n",
    "Best parameters for 94 features: {'C': 0.125, 'gamma': 0.03125, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE Models SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "svm_model_RFE8 = svm.SVC()\n",
    "svm_model_RFE8.fit(x_train_RFE8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "svm_model_RFE32 = svm.SVC()\n",
    "svm_model_RFE32.fit(x_train_RFE32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "svm_model_RFE94 = svm.SVC()\n",
    "svm_model_RFE94.fit(x_train_RFE94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA Models SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "svm_model_ANOVA8 = svm.SVC()\n",
    "svm_model_ANOVA8.fit(x_train_ANOVA8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "svm_model_ANOVA32 = svm.SVC()\n",
    "svm_model_ANOVA32.fit(x_train_ANOVA32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "svm_model_ANOVA94 = svm.SVC()\n",
    "svm_model_ANOVA94.fit(x_train_ANOVA94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y_test RFE SVM (NOT USING TEST SET YET!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature RFE:  1.0\n",
      "accuracy for 32 features RFE:  1.0\n",
      "accuracy for 94 features RFE:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_RFE8_svm = svm_model_RFE8.predict(x_train_RFE8) # will do for test data\n",
    "print('accuracy for 8 feature RFE: ',metrics.accuracy_score(y_train, y_predict_RFE8_svm))\n",
    "# 32 features\n",
    "y_predict_RFE32_svm = svm_model_RFE32.predict(x_train_RFE32) # will do for test data\n",
    "print('accuracy for 32 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE32_svm))\n",
    "# 94 features\n",
    "y_predict_RFE94_svm = svm_model_RFE94.predict(x_train_RFE94) # will do for test data\n",
    "print('accuracy for 94 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE94_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y_test ANOVA SVM (NOT USING TEST SET YET!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature ANOVA:  0.8375\n",
      "accuracy for 32 features ANOVA:  0.925\n",
      "accuracy for 94 features ANOVA:  0.9125\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_ANOVA8_svm = svm_model_ANOVA8.predict(x_train_ANOVA8) # will do for test data\n",
    "print('accuracy for 8 feature ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA8_svm))\n",
    "# 32 features\n",
    "y_predict_ANOVA32_svm = svm_model_ANOVA32.predict(x_train_ANOVA32) # will do for test data\n",
    "print('accuracy for 32 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA32_svm))\n",
    "# 94 features\n",
    "y_predict_ANOVA94_svm = svm_model_ANOVA94.predict(x_train_ANOVA94) # will do for test data\n",
    "print('accuracy for 94 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA94_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression \n",
    "\n",
    "Penalty Norm used in the penalization l2\n",
    "\n",
    "C Inverse of regularization strength; smaller values specify\n",
    "stronger regularization\n",
    "0.25, 1, 4, 16, 64, and 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for parameters LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'l2')\n",
    "c_range = [0.25, 1, 4, 16, 64, 256]\n",
    "params_grid_lr = dict(C=c_range)\n",
    "\n",
    "grid_search_lr= GridSearchCV(lr, params_grid_lr, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit LR for RFE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.975\n",
      "Best parameters for 8 features: {'C': 1}\n",
      "Best score for 32 features: 0.9875\n",
      "Best parameters for 32 features: {'C': 0.25}\n",
      "Best score for 94 features: 1.0\n",
      "Best parameters for 94 features: {'C': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_RFE8_lr = grid_search_lr.fit(x_train_RFE8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search_lr.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search_lr.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_RFE32_lr = grid_search_lr.fit(x_train_RFE32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search_lr.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search_lr.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_RFE94_lr = grid_search_lr.fit(x_train_RFE94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search_lr.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit LR for ANOVA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for 8 features: 0.8\n",
      "Best parameters for 8 features: {'C': 1}\n",
      "Best score for 32 features: 0.9125\n",
      "Best parameters for 32 features: {'C': 0.25}\n",
      "Best score for 94 features: 0.9375\n",
      "Best parameters for 94 features: {'C': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "grid_ANOVA8_lr = grid_search_lr.fit(x_train_ANOVA8, y_train.values.ravel())\n",
    "print('Best score for 8 features:',grid_search_lr.best_score_)\n",
    "print('Best parameters for 8 features:',grid_search_lr.best_params_)\n",
    "\n",
    "# 32 features\n",
    "grid_ANOVA32_lr = grid_search_lr.fit(x_train_ANOVA32, y_train.values.ravel())\n",
    "print('Best score for 32 features:',grid_search_lr.best_score_)\n",
    "print('Best parameters for 32 features:',grid_search_lr.best_params_)\n",
    "\n",
    "# 94 features\n",
    "grid_ANOVA94_lr = grid_search_lr.fit(x_train_ANOVA94, y_train.values.ravel())\n",
    "print('Best score for 94 features:',grid_search_lr.best_score_)\n",
    "print('Best parameters for 94 features:',grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make LR models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE Models LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.25, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "lr_model_RFE8 = LogisticRegression(C = 1)\n",
    "lr_model_RFE8.fit(x_train_RFE8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "lr_model_RFE32 = LogisticRegression(C = 0.25)\n",
    "lr_model_RFE32.fit(x_train_RFE32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "lr_model_RFE94 = LogisticRegression(C = 0.25)\n",
    "lr_model_RFE94.fit(x_train_RFE94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA Models LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.25, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 features \n",
    "lr_model_ANOVA8 = LogisticRegression(C = 1)\n",
    "lr_model_ANOVA8.fit(x_train_ANOVA8,y_train.values.ravel())\n",
    "\n",
    "#32 features \n",
    "lr_model_ANOVA32 = LogisticRegression(C = 0.25)\n",
    "lr_model_ANOVA32.fit(x_train_ANOVA32,y_train.values.ravel())\n",
    "\n",
    "#94 features \n",
    "lr_model_ANOVA94 = LogisticRegression(C = 0.25)\n",
    "lr_model_ANOVA94.fit(x_train_ANOVA94,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y_test RFE LR (NOT USING TEST SET YET!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature RFE:  1.0\n",
      "accuracy for 32 features RFE:  1.0\n",
      "accuracy for 94 features RFE:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_RFE8_lr = lr_model_RFE8.predict(x_train_RFE8) # will do for test data\n",
    "print('accuracy for 8 feature RFE: ',metrics.accuracy_score(y_train, y_predict_RFE8_lr))\n",
    "# 32 features\n",
    "y_predict_RFE32_lr = lr_model_RFE32.predict(x_train_RFE32) # will do for test data\n",
    "print('accuracy for 32 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE32_lr))\n",
    "# 94 features\n",
    "y_predict_RFE94_lr = lr_model_RFE94.predict(x_train_RFE94) # will do for test data\n",
    "print('accuracy for 94 features RFE: ',metrics.accuracy_score(y_train, y_predict_RFE94_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y_test ANOVA LR (NOT USING TEST SET YET!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 8 feature ANOVA:  0.825\n",
      "accuracy for 32 features ANOVA:  0.9375\n",
      "accuracy for 94 features ANOVA:  0.9625\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "y_predict_ANOVA8_lr = lr_model_ANOVA8.predict(x_train_ANOVA8) # will do for test data\n",
    "print('accuracy for 8 feature ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA8_lr))\n",
    "# 32 features\n",
    "y_predict_ANOVA32_lr = lr_model_ANOVA32.predict(x_train_ANOVA32) # will do for test data\n",
    "print('accuracy for 32 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA32_lr))\n",
    "# 94 features\n",
    "y_predict_ANOVA94_lr = lr_model_ANOVA94.predict(x_train_ANOVA94) # will do for test data\n",
    "print('accuracy for 94 features ANOVA: ',metrics.accuracy_score(y_train, y_predict_ANOVA94_lr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
